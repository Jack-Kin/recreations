This is a representative list of interesting problems solved.
I document the "patterns" and "tricks" here to reference.
The rule of thumbs is, these are the information during the "aha" moment.

146
design, classic.
--
hashtable, linkedlist.

493
divide and conquer (merge sort).
--
when merging, you can quickly find the count between
left and right part. then merge.

803
reverse thinking. divide and conquer.
--
If you have two hit points, it is very hard to figure out the second
falling region after the first falling region without redo a DFS. TLE.
This is because the first hit can cause non-trivial region change for
the second hit.
Think reversely.
However, the last hit point must be connecting the last falling region
with the final state after all hit points are hit. Then, if you place
the hit point and the falling region back to the picture, you have reduced
the problem to n - 1, because the last hit point falling region cannot
affect the previous hit point falling region (nothing has fallen yet)

44
dp. optimization in transition
--
dp[i][j] = true iff p[0, j) matches s[0, i).
key observation: when p[j - 1] is the '*', the calculation of dp[i][j]
and dp[i-1][j] are related. exploit this.

780
reverse thinking. handling of edge cases.
--
note values are started positive, so given tx, ty, there
is only one possible previous step depending on tx > ty or not.
the question is tx and ty can be huge, so blindly doing tx -= ty
will be slow if tx = 10^9, ty = 1.
it will also involve nasty edge cases when doing tx = tx % ty. this
is because inital state can be anywhere along sx and tx, not necessarily
tx % ty.
the simpliest way to enforce correctness is to do tx = (tx - sx) % ty
to make sure tx will always be >= sx (so we don't go past the inital
state), then reduce tx -= ty.

4
divided and conquer. generalization. handling of edge cases.
--
sometimes it is easier to deal with the general case than the special
case, as it not uncommon in mathematics. instead of finding the median,
it is more streamlined to consider finding the Kth order statistics in the
two sorted array, where 0th largest is the smallest.
when solving two array a, b we cut the smaller array a:
to make reduction converge fast, we take half of a: l = (|a| + 1)/2
if l is larger or equal to k - 1, we set l = k - 1.
the cut point in b will then be k - l, or |b|, if k - l > |b|
the reason for this cut is to divided the entire set into two partitions
(both a and b's first elements contributes to the first partition),
first has k' elements and second has n - k', where k' <= k
when k - l <= |b|, k' = k
when k - l > |b|, k' < k
key observation:
if there is n elements and you are looking for kth
order statistics, and you know for a set S, |S| < k, every element in
S has n - k' + 1 elements outside S greater or equal to e wher k' <= k:
[<-------- k -------->][<------ n - k ------>]
|<--- k' - 1 -->|[****]|<----- rest n - k -->|
 region where S    kth
 elements can be

Then you can completely ignore S and only consider sub problem T \ S with
k - |S|.

10
dp, transition optimization
--
see 44

140
brute force(backtrace), trie
--
usually, there is no magic in solving these problems:
you need to return ALL results, thus you have to exhaustively search
through all possibilites.
the key is how to efficiently search. when reading a prefix,
you should quickly enumerate all possible words starting from this prefix.
this hints a trie.


158
design, iterator pattern
--
still, this is a problem requires considerable communication with
the problem setter: the function is not referential transparent and
return different result with the same call args. keep in mind how
states are maintained.
buffer iterater design. how to use read4 to implement read1? once you
have read1 you have solved readn. The key idea is to maintain a 4-sized
sliding window buffer and populate buffer when calling read1. If the buffer
is depleted and you cannot populate it, this is the end of the file.


321
reverse thinking, greedy, divide and conquer, merge sort
--
if we are to ask constructing the largest number from *one* array instead
of two, this is a much more easier problem to deal with and is much more
isolated.
now how can we reduce the problem from 2 to 1 array? thinking reversely: if
we have a solution for two array, it must be an *interleaving* of some two
subsequence from the two array respectively. in fact, the interleaving is
unique: the two subsequences must be merged in a merge sort way to generate
the optimial. therefore, we know if we can generate all possible subsequences
from both of the array, and their size add up to k, we can simply pick the
best.
but we don't even need to generate all possible subsequences of a fixed length:
to add up to k, we may be considering array 1 giving subsequence of length
l, 2 giving k - l we are only interested in the *best* subsequence of
length l. this reduces the problem of 2 into 1.
to efficiently solve finding the best subsequence of length l in 1 array,
a greedy approach is used:the first element must be the *first* largest
element in range [0, n - l - 1](otherwise, we can cut and paste). After
determined the largest, the second largest is in subproblem [idx, n - l].

644
reverse thinking, two pointers, binary search
--
as other google interview problems, this is again a combination of two
subproblems.
The first is invoking revsere thinking: it is very inefficient to answer:
what is the maximum average I can get if I have k' length contigous sub array
where k' >= k. When stuck, try to reverse the what you have with what you need:
if I have an average value, if it is possible to have a contigous sub array of
some size k' >= k?
This is actually much easier to solve: this involves the classic two pointer
pattern: a window sum = right end of the window sum - left end of the window
sum. One scan of the right end and maintain the min left we have seen and check
the current right - left. This will make sure for every right end, we only
consider the min left end, thus we must see a best window of some size >= k'.
Once this subproblem is in place, we can immediately start binary search all
possible averages. Note the precision and the init max, min.

212
brute force (backtrace), trie
--
classic brute force(usually you cannot avoid brute force if the problem
requires you to output ALL possibilities). Now it boils down to how to search
efficiently.
when starting at a position in the board, use a walker on a trie to
maintain the same prefix as you explore the borad. when examine a
neighbour, use the trie walker to quickly understand the new prefix is any
word's prefix or not. note same cell can be used repeatedly by different
words, so it is suffice to find all words for every cell as starting point.
To optimize, when the trie walker says the prefix is a word, you can
mark it no longer a word to avoid repeatedly pushing back a discovered
word. but you still pay for finding this prefix in future dfs search as the
prefix is not removed from the trie. it is better to implement remove words from
trie and is a good exercise

// TODO
460
LFU Cache	25.2%	Hard
214
Shortest Palindrome
25.2%	Hard
656
Coin Path
25.9%	Hard
308
Range Sum Query 2D - Mutable
26.1%	Hard
269
Alien Dictionary
26.5%	Hard
818
Race Car	26.5%	Hard
719
Find K-th Smallest Pair Distance	27.2%	Hard
336
Palindrome Pairs	27.2%	Hard
391
Perfect Rectangle
27.5%	Hard
685
Redundant Connection II	27.8%	Hard
23
Merge k Sorted Lists	28.3%	Hard
224
Basic Calculator	28.8%	Hard
218
The Skyline Problem	29.1%	Hard
57
Insert Interval	29.1%	Hard
295
Find Median from Data Stream	29.7%	Hard
316
Remove Duplicate Letters
30.5%	Hard
282
Expression Add Operators
30.6%	Hard
327
Count of Range Sum	30.7%	Hard
480
Sliding Window Median	30.9%	Hard
774
Minimize Max Distance to Gas Station
30.9%	Hard
727
Minimum Window Subsequence
31.1%	Hard
358
Rearrange String k Distance Apart
31.5%	Hard
815
Bus Routes	31.5%	Hard
552
Student Attendance Record II	31.7%	Hard
354
Russian Doll Envelopes	32.6%	Hard
330
Patching Array	32.7%	Hard
587
Erect the Fence	33.6%	Hard
363
Max Sum of Rectangle No Larger Than K	33.8%	Hard
411
Minimum Unique Word Abbreviation
33.8%	Hard
483
Smallest Good Base	33.8%	Hard
683
K Empty Slots
34.2%	Hard
239
Sliding Window Maximum	34.3%	Hard
317
Shortest Distance from All Buildings
34.9%	Hard
315
Count of Smaller Numbers After Self	35.0%	Hard
297
Serialize and Deserialize Binary Tree	35.2%	Hard
782
Transform to Chessboard	36.3%	Hard
568
Maximum Vacation Days
37.2%	Hard
329
Longest Increasing Path in a Matrix	37.4%	Hard
42
Trapping Rain Water	37.7%	Hard
407
Trapping Rain Water II	37.9%	Hard
569
Median Employee Salary
38.0%	Hard
128
Longest Consecutive Sequence	38.3%	Hard
340
Longest Substring with At Most K Distinct Characters
38.6%	Hard
679
24 Game	38.9%	Hard
514
Freedom Trail	39.2%	Hard
465
Optimal Account Balancing
39.3%	Hard
305
Number of Islands II
39.7%	Hard
753
Cracking the Safe
39.9%	Hard
272
Closest Binary Search Tree Value II
40.1%	Hard
668
Kth Smallest Number in Multiplication Table	40.1%	Hard
689
Maximum Sum of 3 Non-Overlapping Subarrays	40.9%	Hard
159
Longest Substring with At Most Two Distinct Characters
42.9%	Hard
425
Word Squares
42.9%	Hard
768
Max Chunks To Make Sorted II	43.0%	Hard
471
Encode String with Shortest Length
43.2%	Hard
312
Burst Balloons	43.7%	Hard
726
Number of Atoms	44.0%	Hard
527
Word Abbreviation
44.3%	Hard
778
Swim in Rising Water	44.4%	Hard
302
Smallest Rectangle Enclosing Black Pixels
46.8%	Hard
765
Couples Holding Hands	48.5%	Hard
732
My Calendar III